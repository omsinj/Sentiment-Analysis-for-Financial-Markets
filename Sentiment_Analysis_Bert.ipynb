{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfffb72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:22:07,901 - INFO - Dataset loaded successfully. Shape: (4845, 2)\n",
      "2025-01-26 17:22:07,915 - INFO - Sample data:\n",
      "  Sentiment                                               Text\n",
      "0   neutral  Technopolis plans to develop in stages an area...\n",
      "1  negative  The international electronic industry company ...\n",
      "2  positive  With the new production plant the company woul...\n",
      "3  positive  According to the company 's updated strategy f...\n",
      "4  positive  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'all-data.csv'  # Update with your file path\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Rename columns for clarity\n",
    "df.columns = ['Sentiment', 'Text']\n",
    "\n",
    "# Log dataset details\n",
    "logging.info(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "logging.info(f\"Sample data:\\n{df.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaf16e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:22:31,333 - INFO - Text cleaning complete. Sample cleaned data:\n",
      "                                                Text  \\\n",
      "0  Technopolis plans to develop in stages an area...   \n",
      "1  The international electronic industry company ...   \n",
      "2  With the new production plant the company woul...   \n",
      "3  According to the company 's updated strategy f...   \n",
      "4  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...   \n",
      "\n",
      "                                        Cleaned_Text  \n",
      "0  Technopolis plans to develop in stages an area...  \n",
      "1  The international electronic industry company ...  \n",
      "2  With the new production plant the company woul...  \n",
      "3  According to the company s updated strategy fo...  \n",
      "4  FINANCING OF ASPOCOMP S GROWTH Aspocomp is agg...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a minimal text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "# Apply text cleaning\n",
    "df['Cleaned_Text'] = df['Text'].apply(clean_text)\n",
    "logging.info(f\"Text cleaning complete. Sample cleaned data:\\n{df[['Text', 'Cleaned_Text']].head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5b02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:22:43,235 - INFO - Sentiment mapping applied: {'positive': 2, 'neutral': 1, 'negative': 0}\n"
     ]
    }
   ],
   "source": [
    "# Map sentiments to integers\n",
    "sentiment_mapping = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Log mapping details\n",
    "logging.info(f\"Sentiment mapping applied: {sentiment_mapping}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70d4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:23:02,921 - INFO - Data split complete. Training samples: 3876, Testing samples: 969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Cleaned_Text'], df['Sentiment'], test_size=0.2, random_state=42, stratify=df['Sentiment']\n",
    ")\n",
    "\n",
    "logging.info(f\"Data split complete. Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bb9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:23:51,227 - WARNING - From C:\\Users\\ojaga\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2025-01-26 17:23:53,074 - INFO - Tokenisation complete.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenise the text data\n",
    "def encode_texts(texts, tokenizer, max_len):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "\n",
    "# Define maximum token length\n",
    "max_len = 100\n",
    "\n",
    "# Tokenise training and testing data\n",
    "train_encodings = encode_texts(X_train, tokenizer, max_len)\n",
    "test_encodings = encode_texts(X_test, tokenizer, max_len)\n",
    "\n",
    "logging.info(\"Tokenisation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e8e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:24:48,537 - WARNING - From C:\\Users\\ojaga\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109484547 (417.65 MB)\n",
      "Trainable params: 109484547 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pretrained BERT model with a classification head\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=3  # Three sentiment classes: Positive, Neutral, Negative\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),  # Standard learning rate for fine-tuning\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0304f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:26:23,316 - INFO - Data converted to TensorFlow datasets.\n"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(16)\n",
    "\n",
    "logging.info(\"Data converted to TensorFlow datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372c5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:26:36,122 - INFO - Starting model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 17:26:47,958 - WARNING - From C:\\Users\\ojaga\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "2025-01-26 17:27:02,359 - WARNING - From C:\\Users\\ojaga\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 3422s 14s/step - loss: 0.5464 - accuracy: 0.7786 - val_loss: 0.4263 - val_accuracy: 0.8328\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 3324s 14s/step - loss: 0.2834 - accuracy: 0.8934 - val_loss: 0.4910 - val_accuracy: 0.8029\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 4763s 20s/step - loss: 0.1586 - accuracy: 0.9489 - val_loss: 0.5294 - val_accuracy: 0.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:38:25,705 - INFO - Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "logging.info(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=3,  # Fine-tuning typically needs only a few epochs\n",
    "    batch_size=16\n",
    ")\n",
    "logging.info(\"Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e601c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:38:37,969 - INFO - Evaluating model on test data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 348s 6s/step - loss: 0.5294 - accuracy: 0.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:44:26,187 - INFO - BERT Test Accuracy: 84.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "logging.info(\"Evaluating model on test data...\")\n",
    "results = model.evaluate(test_dataset)\n",
    "logging.info(f\"BERT Test Accuracy: {results[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d6534e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:51:21,674 - INFO - Model and tokenizer saved to 'bert_sentiment_model' directory.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"bert_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"bert_sentiment_model\")\n",
    "logging.info(\"Model and tokenizer saved to 'bert_sentiment_model' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbca1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 20:51:28,690 - INFO - Sample Text: The company's profits have surged this quarter.\n",
      "2025-01-26 20:51:28,691 - INFO - Predicted Sentiment: Positive\n",
      "2025-01-26 20:51:29,706 - INFO - Sample Text: The company is facing significant challenges this year.\n",
      "2025-01-26 20:51:29,707 - INFO - Predicted Sentiment: Neutral\n",
      "2025-01-26 20:51:31,099 - INFO - Sample Text: The financial results are average, with no major surprises.\n",
      "2025-01-26 20:51:31,103 - INFO - Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Prediction function for BERT\n",
    "def predict_sentiment_bert(text, tokenizer, model, max_len=100):\n",
    "    # Tokenise and encode input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    outputs = model(inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    \n",
    "    # Map predictions to sentiment labels\n",
    "    sentiment_labels = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return sentiment_labels[predicted_class]\n",
    "\n",
    "# Test the model\n",
    "sample_texts = [\n",
    "    \"The company's profits have surged this quarter.\",  # Positive\n",
    "    \"The company is facing significant challenges this year.\",  # Negative\n",
    "    \"The financial results are average, with no major surprises.\"  # Neutral\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    prediction = predict_sentiment_bert(text, tokenizer, model)\n",
    "    logging.info(f\"Sample Text: {text}\")\n",
    "    logging.info(f\"Predicted Sentiment: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a896693d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
